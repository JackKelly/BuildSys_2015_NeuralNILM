<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>NeuralNILM</title>

    <meta name="description" content="Deep Neural Networks applied to Energy Disaggregation">
    <meta name="author" content="Jack Kelly">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="bower_components/reveal.js/css/reveal.css">
    <link rel="stylesheet" href="bower_components/reveal.js/css/theme/black.css" id="theme">
    <link rel="stylesheet" href="css/jack.css">
    
    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'bower_components/reveal.js/css/print/pdf.css' : 'bower_components/reveal.js/css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <h1>Neural NILM</h1>
          <h3>Deep Neural Networks Applied To<br>Energy
            Disaggregation</h3>
          <p>
            <small>
              <a href="http://jack-kelly.com">Jack Kelly</a>
              &amp; <a href="http://www.doc.ic.ac.uk/~wjk/">William
                Knottenbelt</a>
              <br>
              Imperial College London              
          </small></p>
          <p>
            <small>

            </small>
          </p>
        </section>

        <section>
          <h2>Energy Disaggregation</h2>
          <img src="images/disag.png" height=550>
        </section>
        
        <section>
          <h2>Aim: Itemised Energy Bills</h2>
          <img src="images/itemised_energy.png" height=550>
        </section>
        
        <section id="outline">
          <h1>Outline</h1>
          <ol style="width:70%">
            <li class="fragment">Why use deep neural nets (DNNs) for
              NILM?</li>
            <!-- Describe *what* DNNs are good at. -->
            <li class="fragment">How DNNs work</li>            
            <li class="fragment">Three DNN architectures for NILM</li>
            <li class="fragment">Data augmentation</li>
            <li class="fragment">Results</li>
            <li class="fragment">Summary</li>            
          </ol>
        </section>

        <!-- ******************************************************
        In this section, describe *what* DNNs are good at (not how). 
        ******************************************************** -->
        
        <section id="why-dnns-for-nilm">
          <h1 class="dim">Outline</h1>
          <ol style="width:70%">
            <li>Why use deep neural nets (DNNs) for NILM?</li>
            <li class="dim">How DNNs work</li>            
            <li class="dim">Three DNN architectures for NILM</li>
            <li class="dim">Data augmentation</li>            
            <li class="dim">Results</li>
            <li class="dim">Summary</li>            
          </ol>
        </section>        
        
        <section id="washer">
          <h1>Name the Appliance?</h1>
          <p class="placeholder"></p>
          <span class="fragment"></span>
          <span class="fragment"></span>          
        </section>

        <section>
          <img src="images/washing-machine-transparent.png" height=560
          style="background-color: rgb(34,34,34); box-shadow: none;">          
        </section>

        <section>
          <h1>Face Recognition</h2>
          <h2 class="fragment">Manual Feature Extraction</h3>
        </section>

        <section>
          <div style="width: 673px; height: 598px; 
                      border: solid white; 
                      margin: auto;">
            
            <img src="images/hart1.jpg"
                 style="margin: 0; 
                        position: absolute; 
                        transform: translate(-50%, 0)">
            <object data="images/hart_circles.svg"
                    class="fragment"
                    style="margin: 0;
                           position: absolute; 
                           transform: translate(-50%,0);" 
                    type="image/svg+xml"></object>
          </div>
          
          <p class="tiny fragment">
            <a href="http://www.georgehart.com/research/hartbiog.html">
              georgehart.com/research/hartbiog.html</a>
          </p>
          
        </section>

        <section>
          <img src="images/hart2.jpg" height=600>
          <p class="tiny">
            <a href="http://scgp.stonybrook.edu/archives/8516">
              scgp.stonybrook.edu/archives/8516</a>
          </p>
        </section>

        <!--
        <section>
          <h1>SIFT</h1>
          <p>Scale-Invariant Feature Transform</p>
          <img src="images/sift_keypoints.jpg">
          <p class="tiny">
            Image from: <a href="http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html">
              OpenCV-Python Tutorials: Introduction to SIFT</a>
          </p>
          <p class="tiny">
              David G. Lowe. <a href="http://dx.doi.org/10.1109/ICCV.1999.790410">Object recognition from local
              scale-invariant
              features</a>. ICCV (1999)
              <br>Cited by 10,106 papers!
          </p>          
        </section>
        -->

        <section>
          <h1>Deep Neural Nets</h1>
          <h2>Automatic Feature Learning</h2>
        </section>
        
        <section>
          <img src="images/faces.png">
          <img class="fragment" src="images/cars.png">
          <img class="fragment" src="images/chairs.png">          
        </section>

        <section>
          <p><strong>ImageNet</strong> Large Scale Visual Recognition
          Challenge (ILSVRC)</p>
          <img src="images/imagenet.png" height=550>
          <p class="tiny">From: Krizhevsky, Sutskever &amp;
          Hinton. <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep
            Convolutional Neural Networks</a>.  NIPS (2012)
            </p>
        </section>
        
        <section>
          <img src="images/imagenetResults.png" width="90%">
          <p class="tiny">Image from <a href="http://devblogs.nvidia.com/parallelforall/mocha-jl-deep-learning-julia/">devblogs.nvidia.com</a></p>
        </section>        


        <section>
          <p><strong>Krizhevsky <em>et al.</em>'s DNN Results on ImageNet 2012</strong></p>
          <img src="images/krizhevskyResults.png" height=550>
          <p class="tiny">Krizhevsky, Sutskever &amp;
          Hinton. <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep
            Convolutional Neural Networks</a>.  NIPS (2012)
            </p>
        </section>

        
        <!-- ******************************************************
                           *HOW* DNNS work...
        ******************************************************** -->
        
        <section id="how-dnns-work">
          <h1 class="dim">Outline</h1>
          <ol style="width:70%">
            <li class="dim">Why use deep neural nets (DNNs) for NILM?</li>
            <li>How DNNs work</li>            
            <li class="dim">Three DNN architectures for NILM</li>
            <li class="dim">Data augmentation</li>
            <li class="dim">Results</li>
            <li class="dim">Summary</li>            
          </ol>
        </section>

        <section>
          <h1>The Artificial Neuron</h1>
          <img src="images/ArtificialNeuronModel.png">
          <p class="tiny">Image adapted from <a href="https://en.wikibooks.org/wiki/File:ArtificialNeuronModel_english.png">WikiMedia Commons image by Chrislb</a></p>
          <!-- TODO:
          ** D3 (low priority): flow of info through neuron **
          -->
        </section>
        
        <section id="neuralnet">
          <h1>Feed Forward Nets</h1>
          <p class="placeholder"></p>
          <span class="fragment"></span>
        </section>

        <section>
          <p><strong>Krizhevsky <em>et al.</em>'s Architecture for ImageNet 2012</strong></p>
          <img src="images/krizhevskyArchitecture.png">
          <p class="tiny">Krizhevsky, Sutskever &amp;
          Hinton. <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep
            Convolutional Neural Networks</a>.  NIPS (2012)
            </p>
        </section>
        
        <section>
          <h1>Training</h1>
          <object data="images/training.svg" type="image/svg+xml"></object>
          <!--
          Need to learn the weights and biases.
          With 100M learnable parameters, it's not tractable to do an 
          exhaustive search or a random search.
          So use gradient descent.
          Back prop.
          ** D3 (low priority): gradient descent & back-prop **
          -->
        </section>
        
        <section id="autoencoder">
          <h1>Autoencoders</h1>
          <p class="placeholder"></p>
          <span class="fragment"></span>
        </section>

        <section>
          <h2>Autoencoder Examples</h2>
          <div style="height: 600px;">
          <img class="fragment current-visible"
               style="position:absolute; transform: translate(-50%, 0);"
               src="images/HintonAE.png" height=560>
          <img class="fragment current-visible"
               style="position:absolute; transform: translate(-50%, 50%);"               
               src="images/HintonAEexamples.png" width=1100>
          </div>
          <p class="tiny">Hinton &amp; Salakhutdinov. <strong>Reducing the
          dimensionality of data with neural
          networks.</strong> <em>Science</em> (2006)</p>
        </section>

        <!--
        <section>
          <h2>Autoencoder Examples</h2>
          <img src="images/learned_features.gif" height=550>
          <p class="tiny">Animation by <a href="http://www.cs.toronto.edu/~ranzato/research/projects.html#sparse_coding">Marc'Aurelio Ranzato</a></p>
        </section>
        -->

        <section>
          <h1>Denoising Autoencoders</h1>
          <img src="images/peppers.png">
          <p class="tiny">Image from <a href="http://www.cs.toronto.edu/~ranzato/research/projects.html">Marc'Aurelio Ranzato</a></p>          
          <p class="tiny">Vincent <em>et al.</em> <strong>Extracting and composing robust features
          with denoising autoencoders.</strong> <em>ICML</em> (2008)</p>
        </section>
        
        <section id="recurrent">
          <h1>Recurrent Neural Nets</h1>
          <p class="placeholder"></p>
          <span class="fragment"></span>
          <span class="fragment"></span>          
        </section>

        <section>
          <h1>Recurrent Neural Nets</h1>
          <p>Long Short-Term Memory (LSTM) Cells</p>
          <img src="images/LSTMcell.png" height=400>
          <p class="tiny">Image
            from <a href="http://blog.otoro.net/page/3/">blog.otoro.net</a></p>
          <p class="tiny">
            Hochreiter &amp; Schmidhuber. <strong>Long short-term memory</strong>. <em>Neural Computation</em> (1997)
          </p>
          <!-- 
          *** D3 (low priority): LSTM animation ***
          -->
        </section>
        
        <section>
          <h2>Recurrent Neural Nets</h2>
          <p> Playing Volleyball   :)</p>
          <video height=500 controls>
            <source src="images/volleyball.mp4" type="video/mp4">
          </video>
          <p class="tiny">
            By <a href="http://blog.otoro.net/2015/03/28/neural-slime-volleyball/">
              hardmaru / ōtoro / 大トロ
            </a>
          </p>
        </section>

        <!-- ******************************************************
                           Three DNN ARCHITECTURES FOR NILM
        ******************************************************** -->
        
        <section id="dnn-architectures-for-nilm">
          <h1 class="dim">Outline</h1>
          <ol style="width:70%">
            <li class="dim">Why use deep neural nets (DNNs) for NILM?</li>
            <li class="dim">How DNNs work</li>            
            <li>Three DNN architectures for NILM
              <ol>
                <li>Recurrent Neural Nets (LSTM)</li>
                <li>Denoising Autoencoder</li>
                <li>'Bounding rectangle' around the target</li>
              </ol>
            </li>
            <li class="dim">Data augmentation</li>            
            <li class="dim">Results</li>
            <li class="dim">Summary</li>            
          </ol>
        </section>        

        <section id="rnns-for-nilm">
          <h1>Recurrent Neural Nets</h1>
          <p class="placeholder"></p>
          <span class="fragment"></span>
          <span class="fragment"></span>
          <span class="fragment"></span>
          <span class="fragment"></span>          
          <!-- 
          ***** D3 (low priority) ******
          Highlight the connections as data flows through, especially
          RNN connections.
          -->
        </section>

        <section id="autoencoder-for-nilm">
          <h1>Denoising Autoencoders</h1>
          <p class="placeholder"></p>
          <span class="fragment"></span>
          <span class="fragment"></span>          
          <span class="fragment"></span>
          <!-- 
          ***** D3 (low priority) ******
          Highlight the connections as data flows through.
          -->
        </section>

        <section id="rectangles-for-nilm">
          <h1>Bounding Rectangle</h1>
          <p class="placeholder"></p>
          <span class="fragment"></span>
          <span class="fragment"></span>
          <span class="fragment"></span>          
          <!-- 
          ***** D3 (low priority) ******
          Highlight the connections as data flows through.
          -->
        </section>


        <!-- ******************************************************
                           DATA AUGMENTATION
        ******************************************************** -->
        
        <section>
          <h1 class="dim">Outline</h1>
          <ol style="width:70%">
            <li class="dim">Why use deep neural nets (DNNs) for NILM?</li>
            <li class="dim">How DNNs work</li>            
            <li class="dim">Three DNN architectures for NILM</li>
            <li>Data augmentation</li>
            <li class="dim">Results</li>
            <li class="dim">Summary</li>            
          </ol>
        </section>        

        <section>
          <h1>DNNs need lots of data!</h1>
        </section>
        
        <section>
          <p><strong>Data Augmentation for Images of Plakton</strong></p>
          <div style="height: 600px;">
            <div class="fragment current-visible" style="position:absolute;">
              <p style="position:absolute; transform: translate(100px, 200px);">
                Raw
              </p>
              <img src="images/plankton_noaug.png"
                   style="transform: translate(60%, 0)"
                   height=550>
            </div>
            <div class="fragment current-visible" style="position:absolute;" >
              <p style="position:absolute; transform: translate(50px, 200px);">
                Augmented
              </p>
              <img src="images/plankton_augmented.png"
                   style="transform: translate(60%, 0)"                   
                   height=550>
            </div>
            <div style="position:absolute; transform: translate(70px, 590px);">
              <p class="tiny" style="text-align:center;">
             From <a href="http://benanne.github.io/2015/03/17/plankton.html">≋ Deep Sea ≋ team (Dieleman <em>et al.</em>)</a> on
              <a href="https://www.kaggle.com/c/datasciencebowl">
                Kaggle National Data Science Bowl Plankton competition
              </a>
              </p>
            </div>

          </div>
        </section>

        <section>
          <h3>Data Augmentation for NILM</h3>
          <ul>
            <li class="fragment">Extract individual appliance
              activations from real data</li>
            <li class="fragment">For each generated example:
              <ul>
                <li class="fragment">Randomly pick which appliances
                to include</li>
                <li class="fragment">Randomly pick individual
                  activations</li>
                <li class="fragment">Randomly align activations</li>
              </ul>
            </li>
          </ul>
          <!-- TODO:
          *** D3 (medium priority): illustrate data augmentation ***
          Maybe just a flow chart: start with real appliance-level
          data, extract activations into a set per appliance type,
          etc...
          Show several examples?
          -->
        </section>



        <!-- ******************************************************
                                   RESULTS
        ******************************************************** -->
        
        <section>
          <h1 class="dim">Outline</h1>
          <ol style="width:70%">
            <li class="dim">Why use deep neural nets (DNNs) for NILM?</li>
            <li class="dim">How DNNs work</li>            
            <li class="dim">Three DNN architectures for NILM</li>
            <li class="dim">Data augmentation</li>
            <li>Results</li>
            <li class="dim">Summary</li>            
          </ol>
        </section>        

        <section>
          <h3>Example Output</h3>
          <div style="height: 600px; width: 1000px;">
            <div class="fragment current-visible" style="position:absolute;">
              <p>LSTM</p>
              <object data="images/net_output_LSTM.svg"
                      type="image/svg+xml" width=1000></object>              
            </div>

            <div class="fragment current-visible" style="position:absolute;">
              <p>Autoencoder</p>
              <object data="images/net_output_AE.svg"
                      type="image/svg+xml" width=1000></object>              
            </div>

            <div class="fragment current-visible" style="position:absolute;">
              <p>Rectangles</p>
              <object data="images/net_output_rectangles.svg"
                      type="image/svg+xml" width=1000></object>              
            </div>            
          </div>
        </section>

        <section>          
          <object data="images/net_output_no_overlap.svg"
                  type="image/svg+xml" width=1000></object>              
        </section>

        <section>
          <h1>Metrics</h1>
        </section>
        
        <section>
          <div style="height: 600px; width: 1000px;">
            <div class="fragment current-visible"
                 style="position:absolute;">
              <p class="tiny"
                 style="position:absolute; transform: translate(0, 0);">
                Metrics on Seen Appliances
              </p>
              <object data="images/train_houses.svg"
                      type="image/svg+xml"
                      style="transform: translate(50%, 0);"
                      width=600></object>
            </div>

            <div class="fragment current-visible"
                 style="position:absolute;">
              <p class="tiny"
                 style="position:absolute; transform: translate(0, 0);">
                Metrics on Unseen Appliances
              </p>
              <object data="images/unseen_houses.svg"
                      type="image/svg+xml"
                      style="transform: translate(50%, 0);"
                      width=600></object>              
            </div>
          </div>
          
        </section>
        

        <!-- ******************************************************
                                   CONCLUSIONS
        ******************************************************** -->
        
        <section>
          <h1 class="dim">Outline</h1>
          <ol style="width:70%">
            <li class="dim">Why use deep neural nets (DNNs) for NILM?</li>
            <li class="dim">How DNNs work</li>            
            <li class="dim">Three DNN architectures for NILM</li>
            <li class="dim">Data augmentation</li>
            <li class="dim">Results</li>
            <li>Summary</li>            
          </ol>
        </section>        

        <section>
          <h1>Summary</h1>
          <ol style="width:70%">
            <li class="fragment">Developed 3 deep neural nets for NILM</li>
            <li class="fragment">They perform better than NILMTK's CO
              or FHMM algorithms (on UK-DALE)</li>
            <li class="fragment">Just scratched the surface!</li>
          </ol>          
        </section>

      </div>

    </div>

    <!-- REVEAL -->
    <script src="bower_components/reveal.js/lib/js/head.min.js"></script>
    <script src="bower_components/reveal.js/js/reveal.js"></script>

    <!-- D3 -->
    <script src="bower_components/d3/d3.js"></script>

    <!-- REVEAL TO D3 -->
    <script src="js/reveal-to-d3-config.js"></script>
    <script src="js/reveal-to-d3.js"></script>
    <script src="js/d3-common.js"></script>    
    <script src="js/d3-plot-power-data.js"></script>
    <script src="js/d3-plot-neural-nets.js"></script>    
    
    <!-- REVEAL INIT -->
    <script src="js/reveal-init.js"></script>
    
  </body>
</html>
